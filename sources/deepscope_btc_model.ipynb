{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load XAU historical data from Yahoo Finance\n",
    "XAU= yf.Ticker(\"^XAU\")\n",
    "data = XAU.history(start=\"2019-01-01\", end=\"2024-01-01\", interval=\"1d\")\n",
    "data['Return'] = data['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more technical indicators\n",
    "close_price = data['Close'].values\n",
    "high_price = data['High'].values\n",
    "low_price = data['Low'].values\n",
    "\n",
    "data['SMA_10'] = ta.SMA(close_price, timeperiod=10)\n",
    "data['SMA_50'] = ta.SMA(close_price, timeperiod=50)\n",
    "data['RSI'] = ta.RSI(close_price, timeperiod=14)\n",
    "data['MACD'], data['MACD_Signal'], _ = ta.MACD(close_price, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "data['BB_upper'], data['BB_middle'], data['BB_lower'] = ta.BBANDS(close_price, timeperiod=20)\n",
    "data['Momentum'] = ta.MOM(close_price, timeperiod=10)\n",
    "data['Volatility'] = ta.ATR(high_price, low_price, close_price, timeperiod=14)  # Added Volatility\n",
    "data['Stochastic'] = ta.STOCH(high_price, low_price, close_price, fastk_period=14, slowk_period=3)[0]  # Added Stochastic\n",
    "data['Previous_Candle_Size'] = abs(data['High'] - data['Low']).shift(1)\n",
    "\n",
    "# Create lag features for capturing trends\n",
    "data['Return_Lag1'] = data['Return'].shift(1)\n",
    "data['RSI_Lag1'] = data['RSI'].shift(1)\n",
    "data['SMA_10_Lag1'] = data['SMA_10'].shift(1)\n",
    "data['SMA_50_Lag1'] = data['SMA_50'].shift(1)\n",
    "\n",
    "# Drop NaN values after adding new features\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = [\n",
    "    'Return', 'SMA_10', 'SMA_50', 'RSI', 'MACD', 'MACD_Signal',\n",
    "    'BB_upper', 'BB_middle', 'BB_lower', 'Momentum', 'Return_Lag1', 'RSI_Lag1',\n",
    "    'SMA_10_Lag1', 'SMA_50_Lag1', 'Volatility', 'Stochastic', 'Previous_Candle_Size'\n",
    "]\n",
    "data['Target'] = np.where(data['Return'].shift(-1) > 0, 1, 0)  # 1 for up, 0 for down\n",
    "\n",
    "X = data[features]\n",
    "y = data['Target']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(XGBClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters from GridSearchCV\n",
    "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the best model found by GridSearchCV\n",
    "# best_xg_model = grid_search.best_estimator_\n",
    "best_xg_model = model\n",
    "\n",
    "# Evaluate xhe model using cross-validation\n",
    "cv_scores = cross_val_score(best_xg_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})\")\n",
    "\n",
    "# Make predictions and evaluate on the test set\n",
    "y_pred = best_xg_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting with updated features and better portfolio simulation\n",
    "capital = 10000  # Initial capital\n",
    "capital_history = []\n",
    "\n",
    "# Map test indices to the original DataFrame\n",
    "test_indices = y_test.index.to_list()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "0.1% FEE\n",
    "\n",
    "Print CSV for checking\n",
    "\n",
    "NAV 10 usd\n",
    "\n",
    "\n",
    "For Hedge Fund\n",
    "\n",
    "CAGR (Return average per year)\n",
    "\n",
    "Max Drawdown\n",
    "\n",
    "Standard Deviation (Both up and down)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Trade logic with stop-loss and take-profit to reduce risk\n",
    "for i in range(len(test_indices) - 1):\n",
    "    current_idx = test_indices[i]\n",
    "    next_idx = test_indices[i + 1]\n",
    "\n",
    "    prediction = best_xg_model.predict([X_test[i]])[0]\n",
    "    price_today = data['Close'].loc[current_idx]\n",
    "    price_next_day = data['Close'].loc[next_idx]\n",
    "\n",
    "    # Set stop-loss and take-profit levels\n",
    "    stop_loss_pct = 0.02  # 1% stop loss\n",
    "    take_profit_pct = 0.05  # 5% take profit\n",
    "\n",
    "    # Long position logic (buy if predicted up)\n",
    "    if prediction == 1:\n",
    "        profit = (price_next_day - price_today) / price_today * capital\n",
    "        if profit < -stop_loss_pct * capital:\n",
    "            profit = -stop_loss_pct * capital  # Stop loss triggered\n",
    "        elif profit > take_profit_pct * capital:\n",
    "            profit = take_profit_pct * capital  # Take profit triggered\n",
    "    else:  # Short position logic (sell if predicted down)\n",
    "        profit = (price_today - price_next_day) / price_today * capital\n",
    "        if profit < -stop_loss_pct * capital:\n",
    "            profit = -stop_loss_pct * capital  # Stop loss triggered\n",
    "        elif profit > take_profit_pct * capital:\n",
    "            profit = take_profit_pct * capital  # Take profit triggered\n",
    "\n",
    "    capital += profit\n",
    "    capital_history.append(capital)\n",
    "\n",
    "\n",
    "# Plot backtest results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(capital_history, label='Portfolio Value')\n",
    "plt.title('Backtest of Enhanced XAUUSD Long/Short Strategy')\n",
    "plt.xlabel('Trade Days')\n",
    "plt.ylabel('Portfolio Value (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def calculate_metrics(returns, risk_free_rate=0.01):\n",
    "    \"\"\"\n",
    "    Calculate Sharpe Ratio, Sortino Ratio, and Maximum Drawdown.\n",
    "\n",
    "    Parameters:\n",
    "        returns (pd.Series): Series of daily returns.\n",
    "        risk_free_rate (float): Risk-free rate for Sharpe Ratio. Defaults to 1% (0.01).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing Sharpe Ratio, Sortino Ratio, and Maximum Drawdown.\n",
    "    \"\"\"\n",
    "    # Annualized risk-free rate (assuming 252 trading days)\n",
    "    risk_free_daily = (1 + risk_free_rate) ** (1 / 252) - 1\n",
    "\n",
    "    # Excess returns\n",
    "    excess_returns = returns - risk_free_daily\n",
    "\n",
    "    # Sharpe Ratio\n",
    "    sharpe_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n",
    "\n",
    "    # Sortino Ratio (downside risk)\n",
    "    downside_returns = returns[returns < 0]\n",
    "    sortino_ratio = excess_returns.mean() / (downside_returns.std() * np.sqrt(252))\n",
    "\n",
    "    # Maximum Drawdown\n",
    "    cumulative_returns = (1 + returns).cumprod()\n",
    "    drawdowns = cumulative_returns / cumulative_returns.cummax() - 1\n",
    "    max_drawdown = drawdowns.min()\n",
    "\n",
    "    results = [\n",
    "        [\"Sharpe Ratio\", f\"{sharpe_ratio:.2f}\"],\n",
    "        [\"Sortino Ratio\", f\"{sortino_ratio:.2f}\"],\n",
    "        [\"Maximum Drawdown\", f\"{max_drawdown:.2%}\"],  # Format as percentage\n",
    "    ]\n",
    "\n",
    "    table = tabulate(results, headers=[\"Metric\", \"Value\"], tablefmt=\"grid\")\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "capital_history_tmp = capital_history.copy()\n",
    "initial_capital = 10000\n",
    "capital_history_tmp.insert(0, initial_capital)\n",
    "\n",
    "results['Date'] = y_test.index\n",
    "results['Return'] = capital_history_tmp\n",
    "results['Percentage return'] = results['Return'].pct_change()\n",
    "results['Percentage return'] = results['Percentage return'].shift(-1)\n",
    "\n",
    "daily_returns = results['Percentage return']\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(daily_returns)\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
